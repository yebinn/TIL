
# soynlpë¡œ ìì—°ì–´ì²˜ë¦¬ ì‹œì‘í•˜ê¸°
* https://github.com/lovit/soynlp


```
!pip install -q 'soynlp[all]'
```

    [33m  soynlp 0.0.46 does not provide the extra 'all'[0m



```
!pip show soynlp
```

    Name: soynlp
    Version: 0.0.46
    Summary: Unsupervised Korean Natural Language Processing Toolkits
    Home-page: https://github.com/lovit/soynlp
    Author: Lovit
    Author-email: soy.lovit@gmail.com
    License: UNKNOWN
    Location: /usr/local/lib/python3.6/dist-packages
    Requires: psutil, numpy
    Required-by: 



```
import pandas as pd
import numpy as np
import re
```


```
df = pd.read_csv('https://s3.ap-northeast-2.amazonaws.com/data10902/petition/petition.csv', 
                 parse_dates=['start', 'end'])
df.shape
```




    (211690, 8)



## ìì‹ ì˜ ê´€ì‹¬ì‚¬ì— ë§ëŠ” ë‹¨ì–´ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.


```
p = r'.*(ëŒë´„|ìœ¡ì•„|ì´ˆë“±|ë³´ìœ¡).*'
care = df[df['title'].str.match(p) |
           df['content'].str.match(p, flags=re.MULTILINE)]
care.shape
```




    (8382, 8)




```
care.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_id</th>
      <th>start</th>
      <th>end</th>
      <th>answered</th>
      <th>votes</th>
      <th>category</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>24</td>
      <td>2017-08-19</td>
      <td>2017-08-26</td>
      <td>0</td>
      <td>53</td>
      <td>ì¼ìë¦¬</td>
      <td>ê³µê³µê¸°ê´€ ë¬´ì¡°ê±´ì ì¸ ì •ê·œì§ì „í™˜ì„ ë°˜ëŒ€í•©ë‹ˆë‹¤.</td>
      <td>í˜„ì •ë¶€ì—ì„œ ì •ê·œì§ ì¼ìë¦¬ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì— ì°¬ì„±í•©ë‹ˆë‹¤. ê·¸ëŸ°ë° ê³µê³µê¸°ê´€ ë¹„ì •ê·œì§ë“¤ì€ ì¸...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>36</td>
      <td>2017-08-19</td>
      <td>2017-08-26</td>
      <td>0</td>
      <td>1</td>
      <td>ì¸ê¶Œ/ì„±í‰ë“±</td>
      <td>í•œêµ­ì±„ì‹ì¸êµ¬ 100ë§Œëª…. í•™êµ ê¸‰ì‹ ë° êµ°ëŒ€ì—ì„œ í˜„ë¯¸ì±„ì‹ ì„ íƒê¶Œì„ ë³´ì¥í•´ì£¼ì‹­ì‹œì˜¤!</td>
      <td>ë¬¸ì¬ì¸ ëŒ€í†µë ¹ë‹˜ê³¼ ê° ì •ë¶€ ì¸ì‚¬ë¶„ë“¤ê»˜ ë§ˆìŒì† ê¹Šì´ ì¡´ê²½ê³¼ ê°ì‚¬ë¥¼ í‘œí•©ë‹ˆë‹¤. ëŒ€í•œë¯¼êµ­...</td>
    </tr>
    <tr>
      <th>23</th>
      <td>45</td>
      <td>2017-08-19</td>
      <td>2017-11-17</td>
      <td>0</td>
      <td>0</td>
      <td>ìœ¡ì•„/êµìœ¡</td>
      <td>ì´ˆë“±í•™êµ êµì‚¬ ì„ìš© ì‹œí—˜ ê´€ë ¨ í•´ê²°ë°©ì•ˆ</td>
      <td>ì´ˆë“±í•™êµ êµì‚¬ ì„ìš© ì‹œí—˜ì„ ìˆ˜ëŠ¥ ì‹œí—˜ ì²˜ëŸ¼ ì „êµ­ ë‹¨ìœ„ë¡œ ì‹¤ì‹œí•˜ê³ ë‚œ í›„ì—\n1ì§€ë§ 2...</td>
    </tr>
    <tr>
      <th>27</th>
      <td>49</td>
      <td>2017-08-19</td>
      <td>2017-11-17</td>
      <td>0</td>
      <td>27</td>
      <td>ì¼ìë¦¬</td>
      <td>ê³µì •í•œì‚¬íšŒ ì ˆì°¨ê°€ ë°”ë¥¸ì‚¬íšŒê°€ ë˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤.</td>
      <td>ë¬¸ì¬ì¸ëŒ€í†µë ¹ê³¼ êµìœ¡ë¶€ì¥ê´€ë‹˜!\nêµì‚¬ ì •ê·œì§ì€ ì„ìš©ê³ ì‹œë¼ëŠ” ì œë„ë¥¼ í†µí•´ ì •êµì‚¬ê°€ ë  ...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>56</td>
      <td>2017-08-19</td>
      <td>2017-11-17</td>
      <td>0</td>
      <td>5</td>
      <td>ë³´ê±´ë³µì§€</td>
      <td>ì¥ì• ì•„ì˜ ìƒíƒœì— ë”°ë¥¸ ì¥ì• ì•„ëŒë´„ë„ìš°ë¯¸ ì •ì±…ì˜ í•œê³„ì— ê´€í•˜ì—¬...ì½ì–´ì£¼ì…¨ìœ¼ë©´ í•˜ê³  ê¸€...</td>
      <td>ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê·¸ëƒ¥ í‰ë²”í•œ ëŒ€í•™ìƒì´ë©°, ê³ ë“±í•™ìƒì¸ ìí 1ê¸‰ ë‚¨ë™ìƒì„ ë‘” ëˆ„ë‚˜ì…...</td>
    </tr>
  </tbody>
</table>
</div>




```
care.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>article_id</th>
      <th>start</th>
      <th>end</th>
      <th>answered</th>
      <th>votes</th>
      <th>category</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>211552</th>
      <td>273198</td>
      <td>2018-06-17</td>
      <td>2018-07-17</td>
      <td>0</td>
      <td>1</td>
      <td>ìœ¡ì•„/êµìœ¡</td>
      <td>ì´ˆë“±í•™êµ ì €í•™ë…„(1í•™ë…„~) êµê³¼ì„œ ë‚´ìš©ì„ íƒ€ì¸ì˜ë„ì›€ì´ ì—†ì´ë„ ê³µë¶€ê°€ ê°€ëŠ¥ë„ë¡ ë§Œë“¤ì–´...</td>
      <td>ì´ì œ ì…í•™ì„ í•´ì„œ ì´ˆë“±í•™êµì—ì„œ ã„±ã„´ì„ ë°°ìš°ëŠ” ì•„ì´ë“¤ì€ ê°™ì€í•™ë…„ íŠ¹íˆìˆ˜í•™ì´ë‚˜ ë‹¤ë¥¸ ì±…...</td>
    </tr>
    <tr>
      <th>211575</th>
      <td>273222</td>
      <td>2018-06-17</td>
      <td>2018-07-17</td>
      <td>0</td>
      <td>47</td>
      <td>ìœ¡ì•„/êµìœ¡</td>
      <td>ë³´ìœ¡êµì‚¬ê°€ í•˜ëŠ” ì¼ì´ ë­”ì§€ ì•Œê³  ê³„ì‹ ê°€ìš”</td>
      <td>ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” ë³´ìœ¡êµì‚¬ë¡œ ì¼í•˜ê³  ìˆëŠ” í•œ ì—¬ì„±ì…ë‹ˆë‹¤.\në³´ìœ¡êµì‚¬ë¡œ ì¼í•˜ë©´ì„œ í˜ë“¤ì–´...</td>
    </tr>
    <tr>
      <th>211599</th>
      <td>273253</td>
      <td>2018-06-17</td>
      <td>2018-07-17</td>
      <td>0</td>
      <td>8</td>
      <td>ìœ¡ì•„/êµìœ¡</td>
      <td>ììœ í•™ê¸°ì œ ì „ë©´ ìˆ˜ì • ìš”ì²­ë“œë¦½ë‹ˆë‹¤</td>
      <td>ì§€ê¸ˆ ì¤‘í•™êµì—ì„œ ì‹œí–‰í•˜ê³ ìˆëŠ” ììœ í•™ê¸°ì œì— ëŒ€í•´ì„œ  ë”  ë‚˜ì€  ë°©ì•ˆì„ ì´ì•¼ê¸°í•˜ê³ ì ...</td>
    </tr>
    <tr>
      <th>211606</th>
      <td>273261</td>
      <td>2018-06-17</td>
      <td>2018-07-17</td>
      <td>0</td>
      <td>218</td>
      <td>ë³´ê±´ë³µì§€</td>
      <td>í˜„ì‹¤ì— ë§ëŠ” ë³´ìœ¡ë£Œ ì§€ì› ìš”ì²­</td>
      <td>ì–´ë¦°ì´ì§‘ì„ 7ì‹œ 30ë¶„ë¶€í„° 19ì‹œ 30ë¶„ê¹Œì§€ ì˜ë¬´ ë³´ìœ¡ì„ í•˜ë¼ í•˜ì‹­ë‹ˆë‹¤~ êµì‚¬ ê·¼ë¬´...</td>
    </tr>
    <tr>
      <th>211616</th>
      <td>273272</td>
      <td>2018-06-17</td>
      <td>2018-07-17</td>
      <td>0</td>
      <td>2</td>
      <td>ìœ¡ì•„/êµìœ¡</td>
      <td>ìë…€ì¥ë ¤ê¸ˆ</td>
      <td>ì•ˆë…•í•˜ì„¸ìš”.ìŒë‘¥ì´ ì•„ë“¤ì„ í‚¤ìš°ëŠ” ì›Œí‚¹ë§˜ì…ë‹ˆë‹¤.\në§ë²Œì´ë¶€ë¶€ë¡œ ì¼ì„ í•˜ë©´ì„œ ìë…€ì¥ë ¤ê¸ˆ...</td>
    </tr>
  </tbody>
</table>
</div>




```
from soynlp.tokenizer import RegexTokenizer, LTokenizer, MaxScoreTokenizer

tokenizer = RegexTokenizer()
tokenizer
```




    <soynlp.tokenizer._tokenizer.RegexTokenizer at 0x7ffa37544a20>




```
# ìƒ˜í”Œë¡œ ë³´ê³  ì‹¶ì€ ì¸ë±ìŠ¤ì˜ ë²ˆí˜¸ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.
sample_index = 211049
```


```
sample_title = care['title'][sample_index]
sample_title
```




    'ì´ˆì¤‘ê³  ë¬´ìƒê¸‰ì‹'




```
sample_content = care['content'][sample_index]
sample_content
```




    'ì „êµ­ì´  ì´ˆë“±ì¤‘ë“±  ë¬´ìƒê¸‰ì‹ì¸ë°\\nëŒ€êµ¬ê²½ë¶ì€  ì˜¬í•´ë¶€í„° ì´ˆë“±ë§Œ ë¬´ìƒì´ê³ \\nì¤‘í•™êµëŠ”  ì™œ    ìœ ìƒì¸ì§€ìš”\\në‚˜ë¼ì—ì„œ  ì§€ì›í•´ì£¼ëŠ”ê±´ë°\\nëŒ€êµ¬ê²½ë¶ë§Œ ì œì™¸ì‹œí‚¨ì´ìœ ëŠ” ë¨¼ê°€ìš”\\nì§€ì—­ìƒê´€ì—†ì´ ë¬´ìƒê¸‰ì‹ì§€ì›í•´ì•¼í•˜ëŠ”ê±° ì•„ë‹Œê°€ìš”'



# í† í°í™”


```
tokened_title = tokenizer.tokenize(sample_title)
tokened_title
```




    ['ì´ˆì¤‘ê³ ', 'ë¬´ìƒê¸‰ì‹']




```
tokened_content = tokenizer.tokenize(sample_content)
tokened_content[:10]
```




    ['ì „êµ­ì´', 'ì´ˆë“±ì¤‘ë“±', 'ë¬´ìƒê¸‰ì‹ì¸ë°', '\\', 'n', 'ëŒ€êµ¬ê²½ë¶ì€', 'ì˜¬í•´ë¶€í„°', 'ì´ˆë“±ë§Œ', 'ë¬´ìƒì´ê³ ', '\\']




```
print(len(tokened_title))
print(len(tokened_content))
```

    2
    28
    

# í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ 
* ê°œí–‰ë¬¸ì ì œê±°


```
def preprocessing(text):
    # ê°œí–‰ë¬¸ì ì œê±°
    text = re.sub('\\\\n', ' ', text)
    return text
```


```
# %timeì„ ì°ì–´ì£¼ë©´ í•´ë‹¹ ì½”ë“œë¥¼ ì‹¤í–‰í•  ë•Œ ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ì¶œë ¥í•´ ì¤ë‹ˆë‹¤
%time sentences = care['content'].apply(preprocessing)
```

    CPU times: user 53.7 ms, sys: 119 Âµs, total: 53.8 ms
    Wall time: 57.2 ms
    


```
%time tokens = sentences.apply(tokenizer.tokenize)
tokens[:3]
```

    CPU times: user 15.3 s, sys: 243 ms, total: 15.5 s
    Wall time: 15.5 s
    




    3     [í˜„ì •ë¶€ì—ì„œ, ì •ê·œì§, ì¼ìë¦¬ë¥¼, ëŠ˜ë¦¬ëŠ”, ê²ƒì—, ì°¬ì„±í•©ë‹ˆë‹¤, ., ê·¸ëŸ°ë°, ê³µê³µê¸°...
    15    [ë¬¸ì¬ì¸, ëŒ€í†µë ¹ë‹˜ê³¼, ê°, ì •ë¶€, ì¸ì‚¬ë¶„ë“¤ê»˜, ë§ˆìŒì†, ê¹Šì´, ì¡´ê²½ê³¼, ê°ì‚¬ë¥¼, ...
    23    [ì´ˆë“±í•™êµ, êµì‚¬, ì„ìš©, ì‹œí—˜ì„, ìˆ˜ëŠ¥, ì‹œí—˜, ì²˜ëŸ¼, ì „êµ­, ë‹¨ìœ„ë¡œ, ì‹¤ì‹œí•˜ê³ ë‚œ...
    Name: content, dtype: object




```
tokens[sample_index][:10]
```




    ['ì „êµ­ì´', 'ì´ˆë“±ì¤‘ë“±', 'ë¬´ìƒê¸‰ì‹ì¸ë°', 'ëŒ€êµ¬ê²½ë¶ì€', 'ì˜¬í•´ë¶€í„°', 'ì´ˆë“±ë§Œ', 'ë¬´ìƒì´ê³ ', 'ì¤‘í•™êµëŠ”', 'ì™œ', 'ìœ ìƒì¸ì§€ìš”']




```
# ê·¸ë˜í”„ì— retina display ì ìš©
%config InlineBackend.figure_format = 'retina'

# ë‚˜ëˆ”ê³ ë”• ì„¤ì¹˜
!apt -qq -y install fonts-nanum > /dev/null
import matplotlib.font_manager as fm
fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
font = fm.FontProperties(fname=fontpath, size=9)
```

    
    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
    



```
!pip install -q 'wordcloud[all]'
```

    [33m  wordcloud 1.4.1 does not provide the extra 'all'[0m



```
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
%matplotlib inline

def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):
    wordcloud = WordCloud(
                        font_path = fontpath,
                        stopwords = STOPWORDS, # í•œêµ­ì–´ëŠ” í•´ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤. í•œêµ­ì–´ë¥¼ ì ìš©í•´ ì£¼ë ¤ë©´ ë³„ë„ ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
                        background_color = backgroundcolor, 
                         width = width, height = height).generate(data)
    plt.figure(figsize = (15 , 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show() 
```


```
# ê²°ê³¼ë¥¼ ì¶œë ¥í•´ ë³´ë©´ ë¶ˆìš©ì–´(STOPWORD)ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.
%time displayWordCloud(' '.join(sentences))
```


![png](output_25_0.png)


    CPU times: user 19.4 s, sys: 928 ms, total: 20.3 s
    Wall time: 20.8 s
    


```
from soynlp.noun import LRNounExtractor
```


```
%%time
noun_extractor = LRNounExtractor(verbose=True)
noun_extractor.train(sentences)
nouns = noun_extractor.extract()
```

    used default noun predictor; Sejong corpus predictor
    used noun_predictor_sejong
    All 2398 r features was loaded
    scanning completed
    (L,R) has (108055, 53386) tokens
    building lr-graph completedCPU times: user 24 s, sys: 456 ms, total: 24.4 s
    Wall time: 24.5 s
    


```
# ì¶”ì¶œëœ ëª…ì‚¬ë¥¼ ì°ì–´ë´…ë‹ˆë‹¤.
%time displayWordCloud(' '.join(nouns))
```


![png](output_28_0.png)


    CPU times: user 1.74 s, sys: 104 ms, total: 1.84 s
    Wall time: 1.85 s
    


```

```
